{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0,'/data1/dbashir/Project/Summer2018/DeepWatershedDetection/lib/utils/')\n",
    "sys.path.insert(0,'/data1/dbashir/Project/Summer2018/DeepWatershedDetection/lib/models/')\n",
    "sys.path.insert(0,'/data1/dbashir/Project/Summer2018/DeepWatershedDetection/lib/datasets/')\n",
    "sys.path.insert(0,'/data1/dbashir/Project/Summer2018/DeepWatershedDetection/lib/main/')\n",
    "sys.path.insert(0,'/data1/dbashir/Project/Summer2018/DeepWatershedDetection/lib/roi_data_layer/')\n",
    "from config import cfg\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dwd_net import build_dwd_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factory import get_imdb\n",
    "from tensorflow.contrib import slim\n",
    "from safe_softmax_wrapper import safe_softmax_cross_entropy_with_logits\n",
    "import roidb as rdl_roidb\n",
    "from layer import RoIDataLayer\n",
    "from prefetch_wrapper import PrefetchWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fcn_groundtruth import stamp_class, stamp_directions, stamp_energy, stamp_bbox,\\\n",
    "    try_all_assign,get_gt_visuals,get_map_visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr_classes = None\n",
    "# - make different FCN architecture available --> RefineNet, DeepLabv3, standard fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(parsed):\n",
    "    args = parsed[0]\n",
    "    print(args)\n",
    "    iteration = 1\n",
    "\n",
    "    np.random.seed(cfg.RNG_SEED)\n",
    "\n",
    "    # load database\n",
    "    imdb, roidb, imdb_val, roidb_val, data_layer, data_layer_val = load_database(args)\n",
    "\n",
    "    global nr_classes\n",
    "    nr_classes = len(imdb._classes)\n",
    "    args.nr_classes.append(nr_classes)\n",
    "\n",
    "    # replaces keywords with function handles in training assignements\n",
    "    save_objectness_function_handles(args,imdb)\n",
    "\n",
    "\n",
    "    # Debug stuffs\n",
    "    #\n",
    "    # try_all_assign(data_layer,args,100)\n",
    "    # dws_list = perform_dws(data[\"dws_energy\"], data[\"class_map\"], data[\"bbox_fcn\"])\n",
    "    #\n",
    "\n",
    "    # def show_image(data, gt_boxes=None):\n",
    "    #     from PIL import Image, ImageDraw\n",
    "    #     if gt_boxes is None:\n",
    "    #         im = Image.fromarray(data[0].astype(\"uint8\"))\n",
    "    #         im.show()\n",
    "    #     else:\n",
    "    #         im = Image.fromarray(data[0].astype(\"uint8\"))\n",
    "    #         draw = ImageDraw.Draw(im)\n",
    "    #         # overlay GT boxes\n",
    "    #         for row in gt_boxes[0]:\n",
    "    #             draw.rectangle(((row[0], row[1]), (row[2], row[3])), fill=\"red\")\n",
    "    #         im.show()\n",
    "    #     return\n",
    "    #\n",
    "    # fetched_dat = data_layer.forward(args, [args.training_assignements[0]], None)\n",
    "\n",
    "    # show_image(fetched_dat[\"data\"],fetched_dat[\"gt_boxes\"])\n",
    "    # show_image(fetched_dat[\"data\"], None)\n",
    "\n",
    "\n",
    "    # tensorflow session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    # input and output tensors\n",
    "    if \"DeepScores\" in args.dataset:\n",
    "        input = tf.placeholder(tf.float32, shape=[None, None, None, 1])\n",
    "        resnet_dir = cfg.PRETRAINED_DIR+\"/DeepScores/\"\n",
    "        refinenet_dir = cfg.PRETRAINED_DIR+\"/DeepScores_semseg/\"\n",
    "\n",
    "    elif \"MUSICMA\" in args.dataset:\n",
    "        input = tf.placeholder(tf.float32, shape=[None, None, None, 1])\n",
    "        resnet_dir = cfg.PRETRAINED_DIR+\"/DeepScores/\"\n",
    "        refinenet_dir = cfg.PRETRAINED_DIR+\"/DeepScores_semseg/\"\n",
    "\n",
    "    else:\n",
    "        input = tf.placeholder(tf.float32, shape=[None, None, None, 3])\n",
    "        resnet_dir = cfg.PRETRAINED_DIR+\"/ImageNet/\"\n",
    "        refinenet_dir = cfg.PRETRAINED_DIR+\"/VOC2012/\"\n",
    "\n",
    "\n",
    "    if not (len(args.training_help) == 1 and args.training_help[0] is None):\n",
    "        # initialize helper_input\n",
    "        helper_input  = tf.placeholder(tf.float32, shape=[None, None, None, input.shape[-1]+1])\n",
    "        feed_head = slim.conv2d(helper_input, input.shape[-1], [3, 3], scope='gt_feed_head')\n",
    "        input = feed_head\n",
    "\n",
    "    print(\"Initializing Model:\" + args.model)\n",
    "    # model has all possible output heads (even if unused) to ensure saving and loading goes smoothly\n",
    "    network_heads, init_fn = build_dwd_net(\n",
    "        input, model=args.model,num_classes=nr_classes, pretrained_dir=resnet_dir, substract_mean=False)\n",
    "\n",
    "\n",
    "\n",
    "    # initialize tasks\n",
    "    preped_assign = []\n",
    "    for assign in args.training_assignements:\n",
    "        [loss, optim, gt_placeholders, scalar_summary_op,images_summary_op, images_placeholders, mask_placholders] = initialize_assignement(assign,imdb,network_heads,sess,data_layer,input,args)\n",
    "        preped_assign.append([loss, optim, gt_placeholders, scalar_summary_op,images_summary_op, images_placeholders, mask_placholders])\n",
    "\n",
    "\n",
    "\n",
    "    # init tensorflow session\n",
    "    saver = tf.train.Saver(max_to_keep=1000)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # load model weights\n",
    "    checkpoint_dir = get_checkpoint_dir(args)\n",
    "    checkpoint_name =  \"backbone\"\n",
    "    if args.continue_training == \"True\":\n",
    "        print(\"Loading checkpoint\")\n",
    "        saver.restore(sess, checkpoint_dir + \"/\" + checkpoint_name)\n",
    "    elif args.pretrain_lvl == \"deepscores_to_musicma\":\n",
    "        pretrained_vars = []\n",
    "        for var in slim.get_model_variables():\n",
    "            if not (\"class_pred\" in var.name):\n",
    "                pretrained_vars.append(var)\n",
    "        print(\"Loading network pretrained on Deepscores for Muscima\")\n",
    "        loading_checkpoint_name = cfg.PRETRAINED_DIR+\"/DeepScores_to_Muscima/\" + \"backbone\"\n",
    "        init_fn = slim.assign_from_checkpoint_fn(loading_checkpoint_name, pretrained_vars)\n",
    "        init_fn(sess)\n",
    "\n",
    "    else:\n",
    "        if args.pretrain_lvl == \"semseg\":\n",
    "            #load all variables except the ones in scope \"deep_watershed\"\n",
    "            pretrained_vars = []\n",
    "            for var in slim.get_model_variables():\n",
    "                if not(\"deep_watershed\" in var.name or \"gt_feed_head\" in var.name):\n",
    "                    pretrained_vars.append(var)\n",
    "\n",
    "            print(\"Loading network pretrained on semantic segmentation\")\n",
    "            loading_checkpoint_name = refinenet_dir + args.model + \".ckpt\"\n",
    "            init_fn = slim.assign_from_checkpoint_fn(loading_checkpoint_name, pretrained_vars)\n",
    "            init_fn(sess)\n",
    "        elif args.pretrain_lvl == \"class\":\n",
    "            print(\"Loading pretrained weights for level: \" + args.pretrain_lvl)\n",
    "            init_fn(sess)\n",
    "        else:\n",
    "            print(\"Not loading a pretrained network\")\n",
    "\n",
    "    # set up tensorboard\n",
    "    writer = tf.summary.FileWriter(checkpoint_dir, sess.graph)\n",
    "\n",
    "    # execute tasks\n",
    "    for do_a in args.do_assign:\n",
    "        assign_nr = do_a[\"assign\"]\n",
    "        do_itr = do_a[\"Itrs\"]\n",
    "        training_help = args.training_help[do_a[\"help\"]]\n",
    "        iteration = execute_assign(args,input,saver, sess, checkpoint_dir, checkpoint_name, data_layer, writer, network_heads,\n",
    "                                   do_itr,args.training_assignements[assign_nr],preped_assign[assign_nr],iteration,training_help)\n",
    "\n",
    "\n",
    "    # execute combined tasks\n",
    "    for do_comb_a in args.combined_assignements:\n",
    "        #iteration = execute_combined_assign(do_comb_a)\n",
    "        do_comb_itr = do_comb_a[\"Itrs\"]\n",
    "        rm_length = do_comb_a[\"Running_Mean_Length\"]\n",
    "        loss_factors = do_comb_a[\"loss_factors\"]\n",
    "        orig_assign = [args.training_assignements[i] for i in do_comb_a[\"assigns\"]]\n",
    "        preped_assigns = [preped_assign[i] for i in do_comb_a[\"assigns\"]]\n",
    "        training_help = None # unused atm\n",
    "        execute_combined_assign(args,data_layer,training_help,orig_assign,preped_assigns,loss_factors,do_comb_itr,iteration,input,rm_length,\n",
    "                            network_heads,sess,checkpoint_dir,checkpoint_name,saver,writer)\n",
    "\n",
    "    print(\"done :)\")\n",
    "\n",
    "    # traind on combined assigns\n",
    "    # for comb_assign in args.combined_assignements:\n",
    "    #     train_on_comb_assignment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_combined_assign(args,data_layer,training_help,orig_assign,preped_assigns,loss_factors,do_comb_itr,iteration,input_ph,rm_length,\n",
    "                            network_heads,sess,checkpoint_dir,checkpoint_name,saver,writer):\n",
    "\n",
    "    # init data layer\n",
    "    if args.prefetch == \"True\":\n",
    "        data_layer = PrefetchWrapper(data_layer.forward, args.prefetch_len, args, orig_assign, training_help)\n",
    "\n",
    "    # combine losses\n",
    "    past_losses = np.ones((len(loss_factors), rm_length), np.float32)\n",
    "    loss_scalings_placeholder = tf.placeholder(tf.float32,[len(loss_factors)])\n",
    "    loss_tot = None\n",
    "    for i in range(len(preped_assigns)):\n",
    "        if loss_tot is None:\n",
    "            loss_tot = preped_assigns[i][0]*loss_scalings_placeholder[i]\n",
    "        else:\n",
    "            loss_tot += preped_assigns[i][0] * loss_scalings_placeholder[i]\n",
    "\n",
    "    # init optimizer\n",
    "    with tf.variable_scope(\"combined_opt\"+str(0)):\n",
    "        var_list = [var for var in tf.trainable_variables()]\n",
    "        optim = tf.train.RMSPropOptimizer(learning_rate=args.learning_rate, decay=0.995).minimize(loss_tot, var_list=var_list)\n",
    "    opt_inizializers = [var.initializer for var in tf.global_variables() if \"combined_opt\"+str(0) in var.name]\n",
    "    sess.run(opt_inizializers)\n",
    "    # compute step\n",
    "    print(\"training on combined assignments\")\n",
    "    print(\"for \" + str(do_comb_itr) + \" iterations\")\n",
    "\n",
    "    # waste elements off queue because queue clear does not work\n",
    "    for i in range(14):\n",
    "        data_layer.forward(args, orig_assign, training_help)\n",
    "\n",
    "\n",
    "    for itr in range(iteration, (iteration + do_comb_itr)):\n",
    "        # load batch - only use batches with content\n",
    "        batch_not_loaded = True\n",
    "        while batch_not_loaded:\n",
    "            blob = data_layer.forward(args, orig_assign, training_help)\n",
    "            batch_not_loaded = len(blob[\"gt_boxes\"].shape) != 3 or  sum([\"assign\" in key for key in  blob .keys()]) != len(preped_assigns)\n",
    "\n",
    "\n",
    "        if blob[\"helper\"] is not None:\n",
    "            input_data = np.concatenate([blob[\"data\"], blob[\"helper\"]], -1)\n",
    "            feed_dict = {input_ph: input_data}\n",
    "        else:\n",
    "            # pad input with zeros\n",
    "            # input_data = np.concatenate([blob[\"data\"]*0, blob[\"data\"]*0], -1)\n",
    "            # feed_dict = {input: blob[\"data\"], helper_input: input_data}\n",
    "            if len(args.training_help) == 1:\n",
    "                feed_dict = {input_ph: blob[\"data\"]}\n",
    "            else:\n",
    "                # pad input with zeros\n",
    "                input_data = np.concatenate([blob[\"data\"], blob[\"data\"] * 0], -1)\n",
    "                feed_dict = {input_ph: input_data}\n",
    "\n",
    "\n",
    "        for i1 in range(len(preped_assigns)):\n",
    "            gt_placeholders = preped_assigns[i1][2]\n",
    "            mask_placeholders = preped_assigns[i1][6]\n",
    "            for i2 in range(len(gt_placeholders)):\n",
    "                # only one assign\n",
    "                feed_dict[gt_placeholders[i2]] = blob[\"assign\"+str(i1)][\"gt_map\" + str(len(gt_placeholders) - i2 - 1)]\n",
    "                feed_dict[mask_placeholders[i2]] = blob[\"assign\" + str(i1)][\"mask\" + str(len(gt_placeholders) - i2 - 1)]\n",
    "\n",
    "        # compute running mean for losses\n",
    "        feed_dict[loss_scalings_placeholder] = loss_factors/np.maximum(np.mean(past_losses,1),[1.0E-6,1.0E-6,1.0E-6])\n",
    "\n",
    "        # train step\n",
    "        fetch_list = list()\n",
    "        fetch_list.append(optim)\n",
    "        fetch_list.append(loss_tot)\n",
    "        for preped_a in preped_assigns:\n",
    "            fetch_list.append(preped_a[0])\n",
    "        fetches = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "\n",
    "        past_losses[:,:-1] = past_losses[:,1:] # move by one timestep\n",
    "        past_losses[:,-1] = fetches[-3:] # add latest loss\n",
    "\n",
    "        if itr % args.print_interval == 0 or itr == 1:\n",
    "            print(\"loss at itr: \" + str(itr))\n",
    "            print(fetches[1])\n",
    "            print(past_losses)\n",
    "\n",
    "\n",
    "        if itr % args.tensorboard_interval == 0 or itr == 1:\n",
    "            for i in range(len(preped_assigns)):\n",
    "                _, _, _, scalar_summary_op, images_summary_op, images_placeholders, _ = preped_assigns[i]\n",
    "                post_assign_to_tensorboard(orig_assign[i],i,scalar_summary_op,network_heads,feed_dict,itr,sess,writer,blob,images_placeholders,images_summary_op)\n",
    "\n",
    "        if itr % args.save_interval == 0:\n",
    "            print(\"saving weights\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver.save(sess, checkpoint_dir + \"/\" + checkpoint_name)\n",
    "\n",
    "\n",
    "    iteration = (iteration + do_comb_itr)\n",
    "    if args.prefetch == \"True\":\n",
    "        data_layer.kill()\n",
    "\n",
    "    return iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_assign_to_tensorboard(assign,assign_nr,scalar_summary_op,network_heads,feed_dict,itr,sess,writer,blob,images_placeholders,images_summary_op):\n",
    "    fetch_list = [scalar_summary_op]\n",
    "    # fetch sub_predicitons\n",
    "    nr_feature_maps = len(network_heads[assign[\"stamp_func\"][0]][assign[\"stamp_args\"][\"loss\"]])\n",
    "\n",
    "    [fetch_list.append(\n",
    "        network_heads[assign[\"stamp_func\"][0]][assign[\"stamp_args\"][\"loss\"]][nr_feature_maps - (x + 1)]) for x\n",
    "        in\n",
    "        range(len(assign[\"ds_factors\"]))]\n",
    "\n",
    "    summary = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "    writer.add_summary(summary[0], float(itr))\n",
    "\n",
    "    # use predicted feature maps\n",
    "    # TODO predict boxes\n",
    "\n",
    "    # debug logits\n",
    "    # if itr ==1:\n",
    "    #     hist_ph = tf.placeholder(tf.uint8, shape=[1, summary[1].shape[3]])\n",
    "    #     logits_sum = tf.summary.histogram('logits_means', hist_ph)\n",
    "    #\n",
    "    # h_sum = sess.run([logits_sum], feed_dict={hist_ph: np.mean(summary[1],(1,2))})\n",
    "    # writer.add_summary(h_sum[0], float(itr))\n",
    "\n",
    "\n",
    "    gt_visuals = get_gt_visuals(blob, assign, assign_nr, pred_boxes=None, show=False)\n",
    "    map_visuals = get_map_visuals(summary[1:], assign, show=False)\n",
    "    images_feed_dict = get_images_feed_dict(assign, blob, gt_visuals, map_visuals, images_placeholders)\n",
    "    # save images to tensorboard\n",
    "    summary = sess.run([images_summary_op], feed_dict=images_feed_dict)\n",
    "    writer.add_summary(summary[0], float(itr))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_assignement(assign,imdb,network_heads,sess,data_layer,input,args):\n",
    "    gt_placeholders = get_gt_placeholders(assign,imdb)\n",
    "\n",
    "    loss_mask_placeholders = [tf.placeholder(tf.float32, shape=[None, None,1]) for x in assign[\"ds_factors\"]]\n",
    "\n",
    "    debug_fetch = dict()\n",
    "\n",
    "    if assign[\"stamp_func\"][0] == \"stamp_directions\":\n",
    "        loss_components = []\n",
    "        for x in range(len(assign[\"ds_factors\"])):\n",
    "            debug_fetch[str(x)] = dict()\n",
    "            # # mask, where gt is zero\n",
    "            split1, split2 = tf.split(gt_placeholders[x],2,-1)\n",
    "            debug_fetch[str(x)][\"split1\"] = split1\n",
    "\n",
    "            mask = tf.squeeze(split1 > 0, -1)\n",
    "            debug_fetch[str(x)][\"mask\"] = mask\n",
    "\n",
    "            masked_pred = tf.boolean_mask(network_heads[assign[\"stamp_func\"][0]][assign[\"stamp_args\"][\"loss\"]][x], mask)\n",
    "            debug_fetch[str(x)][\"masked_pred\"]= masked_pred\n",
    "\n",
    "            masked_gt = tf.boolean_mask(gt_placeholders[x], mask)\n",
    "            debug_fetch[str(x)][\"masked_gt\"] = masked_gt\n",
    "\n",
    "            # norm prediction\n",
    "            norms = tf.norm(masked_pred,ord=\"euclidean\",axis=-1,keep_dims=True)\n",
    "            masked_pred = masked_pred/norms\n",
    "            debug_fetch[str(x)][\"masked_pred_normed\"] = masked_pred\n",
    "\n",
    "            # inner product\n",
    "            # inner = tf.diag_part(tf.tensordot(masked_gt,tf.transpose(masked_pred),1))\n",
    "            # debug_fetch[str(x)][\"inner\"] = inner\n",
    "\n",
    "            gt_1, gt_2 = tf.split(masked_gt, 2, -1)\n",
    "            pred_1, pred_2 = tf.split(masked_pred, 2, -1)\n",
    "            inner_2 = gt_1*pred_1+gt_2*pred_2\n",
    "            debug_fetch[str(x)][\"inner_2\"] = inner_2\n",
    "            # round to 4 digits after dot\n",
    "            # multiplier = tf.constant(10 ** 4, dtype=tf.float32)\n",
    "            # inner_rounded = tf.round(inner_2 * multiplier) / multiplier\n",
    "            # debug_fetch[str(x)][\"inner_rounded\"] = inner_rounded\n",
    "\n",
    "            # cap to [-1,1] due to numerical instability\n",
    "\n",
    "            inner_2 = tf.maximum(tf.constant(-1, dtype=tf.float32),tf.minimum(tf.constant(1, dtype=tf.float32),inner_2))\n",
    "\n",
    "            acos_inner = tf.acos(inner_2)\n",
    "            debug_fetch[str(x)][\"acos_inner\"] = acos_inner\n",
    "\n",
    "            loss_components.append(acos_inner)\n",
    "    else:\n",
    "        nr_feature_maps = len(network_heads[assign[\"stamp_func\"][0]][assign[\"stamp_args\"][\"loss\"]])\n",
    "        nr_ds_factors = len(assign[\"ds_factors\"])\n",
    "        if assign[\"stamp_args\"][\"loss\"] == \"softmax\":\n",
    "            # loss_components = [safe_softmax_cross_entropy_with_logits(logits=network_heads[assign[\"stamp_func\"][0]][assign[\"stamp_args\"][\"loss\"]][nr_feature_maps-nr_ds_factors+x],\n",
    "            #                                                 labels=gt_placeholders[x]) for x in range(nr_ds_factors)]\n",
    "            loss_components = [tf.nn.softmax_cross_entropy_with_logits(logits=network_heads[assign[\"stamp_func\"][0]][assign[\"stamp_args\"][\"loss\"]][nr_feature_maps-nr_ds_factors+x],\n",
    "                                                            labels=gt_placeholders[x], dim=-1) for x in range(nr_ds_factors)]\n",
    "            debug_fetch[\"loss_components_softmax\"] = loss_components\n",
    "        else:\n",
    "            loss_components = [tf.losses.mean_squared_error(\n",
    "                predictions=network_heads[assign[\"stamp_func\"][0]][assign[\"stamp_args\"][\"loss\"]][nr_feature_maps-nr_ds_factors+x],\n",
    "                labels=gt_placeholders[x],reduction=\"none\") for x in range(nr_ds_factors)]\n",
    "            debug_fetch[\"loss_components_mse\"] = loss_components\n",
    "\n",
    "    comp_multy = []\n",
    "    for i in range(len(loss_components)):\n",
    "        # maybe expand dims\n",
    "        if len(loss_components[i][0].shape)==2:\n",
    "            cond_result = tf.expand_dims(loss_components[i][0], -1)\n",
    "        else:\n",
    "            cond_result = loss_components[i][0]\n",
    "        comp_multy.append(tf.multiply(cond_result, loss_mask_placeholders[i]))\n",
    "        # debug_fetch[\"loss_components_multy\"+str(i)] = tf.multiply(loss_components[i], loss_mask_placeholders[i])\n",
    "        # debug_fetch[\"loss_components_multyaaaa\" + str(i)] = tf.multiply(loss_components[i], 3)\n",
    "    # call tf.reduce mean on each loss component\n",
    "    final_loss_components = [tf.reduce_mean(x) for x in comp_multy]\n",
    "\n",
    "    #################################################################################################################\n",
    "    # debug  losses\n",
    "    # load batch - only use batches with content\n",
    "    # batch_not_loaded = True\n",
    "    # while batch_not_loaded:\n",
    "    #\n",
    "    #     blob = data_layer.forward(args, [assign], None)\n",
    "    #     batch_not_loaded = len(blob[\"gt_boxes\"].shape) != 3\n",
    "    #\n",
    "    #     feed_dict = {input: blob[\"data\"]}\n",
    "    #     for i in range(len(gt_placeholders)):\n",
    "    #         feed_dict[gt_placeholders[i]] = blob[\"assign0\"][\"gt_map\" + str(len(gt_placeholders)-i-1)]\n",
    "    #         feed_dict[loss_mask_placeholders[i]] = blob[\"assign0\"][\"mask\" + str(len(gt_placeholders) - i - 1)]\n",
    "    #\n",
    "    # sess.run(tf.global_variables_initializer())\n",
    "    # 1==1\n",
    "    # # train softmax\n",
    "    # loss_fetch = sess.run([final_loss_components,comp_multy,\n",
    "    #                        loss_components], feed_dict=feed_dict)\n",
    "    # loss_comp_final, comp_mul, loss_mse = loss_fetch\n",
    "    #\n",
    "    # loss_fetch = sess.run([loss_components], feed_dict=feed_dict)\n",
    "\n",
    "\n",
    "    # from PIL import Image\n",
    "    # Image.fromarray(np.squeeze(blob[\"assign0\"][\"mask\" + str(len(gt_placeholders) - i - 1)],-1).astype(np.uint8)).show()\n",
    "    # Image.fromarray(np.squeeze(blob[\"data\"],-1).astype(np.uint8)[0]).show()\n",
    "    # loss_fetch  = np.squeeze((loss_fetch[0][0]/np.amax(loss_fetch[0][0])*255).astype(np.uint8),-1)\n",
    "    # Image.fromarray(loss_fetch).show()\n",
    "    #\n",
    "    #\n",
    "    # feature_maps_fetch = sess.run(network_heads[assign[\"stamp_func\"][0]][assign[\"stamp_args\"][\"loss\"]], feed_dict=feed_dict)\n",
    "    # for map in feature_maps_fetch:\n",
    "    #     print(map.shape)\n",
    "    #\n",
    "    # # train step\n",
    "    #\n",
    "    # [split] = sess.run([debug_fetch[str(x)][\"split1\"]], feed_dict=feed_dict)\n",
    "    # [pred] = sess.run([network_heads[assign[\"stamp_func\"][0]][x]], feed_dict=feed_dict)\n",
    "    # [mask] = sess.run([debug_fetch[str(x)][\"mask\"]], feed_dict=feed_dict)\n",
    "    # [masked_gt] = sess.run([debug_fetch[str(x)][\"masked_gt\"]], feed_dict=feed_dict)\n",
    "    # [masked_pred_normed] = sess.run([debug_fetch[str(x)][\"masked_pred_normed\"]], feed_dict=feed_dict)\n",
    "    # [inner] = sess.run([debug_fetch[str(x)][\"inner\"]], feed_dict=feed_dict)\n",
    "    # [inner_2] = sess.run([debug_fetch[str(x)][\"inner_2\"]], feed_dict=feed_dict)\n",
    "    # [inner_rounded] = sess.run([debug_fetch[str(x)][\"inner_rounded\"]], feed_dict=feed_dict)\n",
    "    # debug_fetch[str(x)].keys()\n",
    "    # #################################################################################################################\n",
    "\n",
    "    # TODO replace by weight mask\n",
    "    # # potentially mask out zeros\n",
    "    # if assign[\"mask_zeros\"]:\n",
    "    #     # only compute loss where GT is not zero intended for \"directional donuts\"\n",
    "    #     masked_components = []\n",
    "    #     for x in range(len(assign[\"ds_factors\"])):\n",
    "    #         mask = tf.squeeze(gt_placeholders[x] > 0, -1)\n",
    "    #         masked_components.append(tf.boolean_mask(loss_components[x], mask))\n",
    "    #\n",
    "    #     loss_components = masked_components\n",
    "\n",
    "\n",
    "\n",
    "    # replace with loss of last layer if is nan (can happen if last mask has no directions on it)\n",
    "    #loss_components = [tf.cond(tf.is_nan(x), lambda: loss_components[len(loss_components)-1], lambda: x) for x in loss_components]\n",
    "\n",
    "    stacked_components = tf.stack(final_loss_components)\n",
    "\n",
    "\n",
    "    if assign[\"layer_loss_aggregate\"] == \"min\":\n",
    "        loss = tf.reduce_min(stacked_components)\n",
    "    elif assign[\"layer_loss_aggregate\"] == \"avg\":\n",
    "        loss = tf.reduce_mean(stacked_components)\n",
    "    else:\n",
    "        raise NotImplementedError(\"unknown layer aggregate\")\n",
    "\n",
    "\n",
    "    # init optimizer\n",
    "    var_list = [var for var in tf.trainable_variables()]\n",
    "    optim = tf.train.RMSPropOptimizer(learning_rate=args.learning_rate, decay=0.995).minimize(loss, var_list=var_list)\n",
    "\n",
    "\n",
    "    # init summary operations\n",
    "    # define summary ops\n",
    "    scalar_sums = []\n",
    "\n",
    "    scalar_sums.append(tf.summary.scalar(\"loss \" + get_config_id(assign)+\":\", loss))\n",
    "\n",
    "    for comp_nr in range(len(loss_components)):\n",
    "        scalar_sums.append(tf.summary.scalar(\"loss_component \" + get_config_id(assign) + \"Nr\"+str(comp_nr)+\":\", final_loss_components[comp_nr]))\n",
    "\n",
    "    scalar_summary_op = tf.summary.merge(scalar_sums)\n",
    "\n",
    "\n",
    "\n",
    "    images_sums = []\n",
    "    images_placeholders = []\n",
    "\n",
    "    # feature maps\n",
    "    for i in range(len(assign[\"ds_factors\"])):\n",
    "        sub_prediction_placeholder = tf.placeholder(tf.uint8, shape=[1, None, None, 3])\n",
    "        images_placeholders.append(sub_prediction_placeholder)\n",
    "        images_sums.append(tf.summary.image('sub_prediction_' + str(i)+\"_\"+get_config_id(assign), sub_prediction_placeholder))\n",
    "\n",
    "\n",
    "    helper_img = tf.placeholder(tf.uint8, shape=[1, None, None, 1])\n",
    "    images_placeholders.append(helper_img)\n",
    "    images_sums.append(tf.summary.image('helper' + str(i)+get_config_id(assign), helper_img))\n",
    "\n",
    "\n",
    "    final_pred_placeholder = tf.placeholder(tf.uint8, shape=[1, None, None, 3])\n",
    "    images_placeholders.append(final_pred_placeholder)\n",
    "    images_sums.append(tf.summary.image('final_predictions_' + str(i)+get_config_id(assign), final_pred_placeholder))\n",
    "    images_summary_op = tf.summary.merge(images_sums)\n",
    "\n",
    "    return loss, optim, gt_placeholders, scalar_summary_op,images_summary_op, images_placeholders, loss_mask_placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_assign(args,input,saver, sess, checkpoint_dir, checkpoint_name, data_layer, writer, network_heads,\n",
    "                   do_itr, assign, prepped_assign, iteration,training_help):\n",
    "    loss, optim, gt_placeholders, scalar_summary_op, images_summary_op, images_placeholders, mask_placeholders = prepped_assign\n",
    "\n",
    "    if args.prefetch == \"True\":\n",
    "        data_layer = PrefetchWrapper(data_layer.forward, args.prefetch_len, args, [assign], training_help)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"training on:\" + str(assign))\n",
    "    print(\"for \" + str(do_itr)+ \" iterations\")\n",
    "    for itr in range(iteration, (iteration + do_itr)):\n",
    "        # load batch - only use batches with content\n",
    "        batch_not_loaded = True\n",
    "        while batch_not_loaded:\n",
    "            blob = data_layer.forward(args, [assign], training_help)\n",
    "            if int(gt_placeholders[0].shape[-1]) != blob[\"assign0\"][\"gt_map0\"].shape[-1] or len(blob[\"gt_boxes\"].shape) != 3:\n",
    "                print(\"skipping queue element\")\n",
    "            else:\n",
    "                batch_not_loaded = False\n",
    "\n",
    "\n",
    "        if blob[\"helper\"] is not None:\n",
    "            input_data = np.concatenate([blob[\"data\"],blob[\"helper\"]],-1)\n",
    "            feed_dict = {input: input_data}\n",
    "        else:\n",
    "            # pad input with zeros\n",
    "            # input_data = np.concatenate([blob[\"data\"]*0, blob[\"data\"]*0], -1)\n",
    "            # feed_dict = {input: blob[\"data\"], helper_input: input_data}\n",
    "            if len(args.training_help) == 1:\n",
    "                feed_dict = {input: blob[\"data\"]}\n",
    "            else:\n",
    "                # pad input with zeros\n",
    "                input_data = np.concatenate([blob[\"data\"], blob[\"data\"]*0], -1)\n",
    "                feed_dict = {input: input_data}\n",
    "\n",
    "        for i in range(len(gt_placeholders)):\n",
    "            # only one assign\n",
    "            feed_dict[gt_placeholders[i]] = blob[\"assign0\"][\"gt_map\" + str(len(gt_placeholders)-i-1)]\n",
    "            feed_dict[mask_placeholders[i]] = blob[\"assign0\"][\"mask\" + str(len(gt_placeholders) - i - 1)]\n",
    "\n",
    "\n",
    "        # train step\n",
    "        _, loss_fetch = sess.run([optim, loss], feed_dict=feed_dict)\n",
    "\n",
    "        if itr % args.print_interval == 0 or itr == 1:\n",
    "            print(\"loss at itr: \" + str(itr))\n",
    "            print(loss_fetch)\n",
    "\n",
    "        if itr % args.tensorboard_interval == 0 or itr == 1:\n",
    "            fetch_list = [scalar_summary_op]\n",
    "            # fetch sub_predicitons\n",
    "            nr_feature_maps = len(network_heads[assign[\"stamp_func\"][0]][assign[\"stamp_args\"][\"loss\"]])\n",
    "\n",
    "            [fetch_list.append(network_heads[assign[\"stamp_func\"][0]][assign[\"stamp_args\"][\"loss\"]][nr_feature_maps-(x+1)]) for x in\n",
    "             range(len(assign[\"ds_factors\"]))]\n",
    "\n",
    "            summary = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "            writer.add_summary(summary[0], float(itr))\n",
    "\n",
    "            # use predicted feature maps\n",
    "            # TODO predict boxes\n",
    "\n",
    "            # debug logits\n",
    "            # if itr ==1:\n",
    "            #     hist_ph = tf.placeholder(tf.uint8, shape=[1, summary[1].shape[3]])\n",
    "            #     logits_sum = tf.summary.histogram('logits_means', hist_ph)\n",
    "            #\n",
    "            # h_sum = sess.run([logits_sum], feed_dict={hist_ph: np.mean(summary[1],(1,2))})\n",
    "            # writer.add_summary(h_sum[0], float(itr))\n",
    "\n",
    "\n",
    "            gt_visuals = get_gt_visuals(blob, assign, 0, pred_boxes=None, show=False)\n",
    "            map_visuals = get_map_visuals(summary[1:], assign, show=False)\n",
    "            images_feed_dict = get_images_feed_dict(assign, blob, gt_visuals, map_visuals, images_placeholders)\n",
    "            # save images to tensorboard\n",
    "            summary = sess.run([images_summary_op], feed_dict=images_feed_dict)\n",
    "            writer.add_summary(summary[0], float(itr))\n",
    "\n",
    "        if itr % args.save_interval == 0:\n",
    "            print(\"saving weights\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver.save(sess, checkpoint_dir + \"/\" + checkpoint_name)\n",
    "\n",
    "    iteration = (iteration + do_itr)\n",
    "    if args.prefetch == \"True\":\n",
    "        data_layer.kill()\n",
    "\n",
    "    return iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_images_feed_dict(assign,blob,gt_visuals,map_visuals,images_placeholders):\n",
    "    feed_dict = dict()\n",
    "    # for i in range(len(assign[\"ds_factors\"])*2):\n",
    "    #     if i%2 ==0:\n",
    "    #         # prediction\n",
    "    #         feed_dict[images_placeholders[i]] = map_visuals[i/2]\n",
    "    #\n",
    "    #     else:\n",
    "    #         feed_dict[images_placeholders[i]] = gt_visuals[i]\n",
    "\n",
    "    # reverse map vis order\n",
    "    for i in range(len(assign[\"ds_factors\"])):\n",
    "        feed_dict[images_placeholders[i]] = np.concatenate([gt_visuals[i], map_visuals[i]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for key in feed_dict.keys():\n",
    "        feed_dict[key] = np.expand_dims(feed_dict[key], 0)\n",
    "\n",
    "    if blob[\"helper\"] is not None:\n",
    "        feed_dict[images_placeholders[len(images_placeholders)-2]] = (blob[\"helper\"]/np.max(blob[\"helper\"])*255).astype(np.uint8)\n",
    "    else:\n",
    "        feed_dict[images_placeholders[len(images_placeholders) - 2]] = np.zeros(blob[\"data\"].shape,dtype=np.uint8)\n",
    "\n",
    "    if blob[\"data\"].shape[3] == 1:\n",
    "        img_data = np.concatenate([blob[\"data\"],blob[\"data\"],blob[\"data\"]],-1).astype(np.uint8)\n",
    "    else:\n",
    "        img_data = blob[\"data\"].astype(np.uint8)\n",
    "    feed_dict[images_placeholders[len(images_placeholders)-1]] = img_data\n",
    "\n",
    "\n",
    "\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gt_placeholders(assign, imdb):\n",
    "    gt_dim = assign[\"stamp_func\"][1](None, assign[\"stamp_args\"], nr_classes)\n",
    "    return [tf.placeholder(tf.float32, shape=[None, None, None, gt_dim]) for x in assign[\"ds_factors\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_config_id(assign):\n",
    "    return assign[\"stamp_func\"][0]+\"_\"+ assign[\"stamp_args\"][\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_checkpoint_dir(args):\n",
    "    # assemble path\n",
    "    if \"DeepScores\" in args.dataset:\n",
    "        image_mode = \"music\"\n",
    "    elif \"MUSICMA\" in args.dataset:\n",
    "        image_mode = \"music_handwritten\"\n",
    "    else:\n",
    "        image_mode = \"realistic\"\n",
    "    tbdir = cfg.EXP_DIR + \"/\" + image_mode +\"/\"+\"pretrain_lvl_\"+args.pretrain_lvl+\"/\" + args.model\n",
    "    if not os.path.exists(tbdir):\n",
    "        os.makedirs(tbdir)\n",
    "    runs_dir = os.listdir(tbdir)\n",
    "    if args.continue_training == \"True\":\n",
    "        tbdir = tbdir + \"/\" + \"run_\" + str(len(runs_dir)-1)\n",
    "    else:\n",
    "        tbdir = tbdir+\"/\"+\"run_\"+str(len(runs_dir))\n",
    "        os.makedirs(tbdir)\n",
    "    return tbdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_roidb(imdb, use_flipped):\n",
    "  \"\"\"Returns a roidb (Region of Interest database) for use in training.\"\"\"\n",
    "  if use_flipped:\n",
    "    print('Appending horizontally-flipped training examples...')\n",
    "    imdb.append_flipped_images()\n",
    "    print('done')\n",
    "\n",
    "  print('Preparing training data...')\n",
    "  rdl_roidb.prepare_roidb(imdb)\n",
    "  print('done')\n",
    "\n",
    "  return imdb.roidb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_objectness_function_handles(args, imdb):\n",
    "    FUNCTION_MAP = {'stamp_directions':stamp_directions,\n",
    "                    'stamp_energy': stamp_energy,\n",
    "                    'stamp_class': stamp_class,\n",
    "                    'stamp_bbox': stamp_bbox\n",
    "                    }\n",
    "\n",
    "    for obj_setting in args.training_assignements:\n",
    "        obj_setting[\"stamp_func\"] = [obj_setting[\"stamp_func\"], FUNCTION_MAP[obj_setting[\"stamp_func\"]]]\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_database(args):\n",
    "    print(\"Setting up image database: \" + args.dataset)\n",
    "    imdb = get_imdb(args.dataset)\n",
    "    print('Loaded dataset `{:s}` for training'.format(imdb.name))\n",
    "    roidb = get_training_roidb(imdb, args.use_flipped == \"True\")\n",
    "    print('{:d} roidb entries'.format(len(roidb)))\n",
    "\n",
    "    if args.dataset_validation != \"no\":\n",
    "        print(\"Setting up validation image database: \" + args.dataset_validation)\n",
    "        imdb_val = get_imdb(args.dataset_validation)\n",
    "        print('Loaded dataset `{:s}` for validation'.format(imdb_val.name))\n",
    "        roidb_val = get_training_roidb(imdb_val, False)\n",
    "        print('{:d} roidb entries'.format(len(roidb_val)))\n",
    "    else:\n",
    "        imdb_val = None\n",
    "        roidb_val = None\n",
    "\n",
    "\n",
    "    data_layer = RoIDataLayer(roidb, imdb.num_classes)\n",
    "\n",
    "    if roidb_val is not None:\n",
    "        data_layer_val = RoIDataLayer(roidb_val, imdb_val.num_classes, random=True)\n",
    "\n",
    "    return imdb, roidb, imdb_val, roidb_val, data_layer, data_layer_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nr_classes():\n",
    "    return nr_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1, combined_assignements=[{'assigns': [0, 1, 2], 'loss_factors': [2, 1, 1], 'Running_Mean_Length': 5, 'Itrs': 30000}], continue_training='False', crop='True', crop_top_left_bias=0.3, dataset='DeepScores_2017_train', dataset_validation='DeepScores_2017_debug', do_assign=[{'assign': 1, 'help': 0, 'Itrs': 5}, {'assign': 0, 'help': 0, 'Itrs': 5}, {'assign': 2, 'help': 0, 'Itrs': 3000}], learning_rate=0.0001, max_edge=960, model='RefineNet-Res101', nr_classes=[], pad_to=160, pad_with=0, prefetch='True', prefetch_len=7, pretrain_lvl='semseg', print_interval=10, save_interval=1000, scale_list=[0.5], substract_mean='False', tensorboard_interval=50, training_assignements=[{'ds_factors': [1], 'downsample_marker': True, 'overlap_solution': 'max', 'stamp_func': 'stamp_energy', 'layer_loss_aggregate': 'avg', 'mask_zeros': False, 'stamp_args': {'marker_dim': (9, 9), 'size_percentage': 0.8, 'shape': 'oval', 'loss': 'softmax', 'energy_shape': 'linear'}}, {'ds_factors': [1], 'downsample_marker': True, 'overlap_solution': 'no', 'stamp_func': 'stamp_class', 'layer_loss_aggregate': 'avg', 'mask_zeros': True, 'stamp_args': {'marker_dim': (9, 9), 'size_percentage': 1, 'shape': 'oval', 'class_resolution': 'class', 'loss': 'softmax'}}, {'ds_factors': [1], 'downsample_marker': True, 'overlap_solution': 'nearest', 'stamp_func': 'stamp_bbox', 'layer_loss_aggregate': 'avg', 'mask_zeros': True, 'stamp_args': {'marker_dim': (9, 9), 'size_percentage': 1, 'shape': 'oval', 'loss': 'reg'}}], training_help=[None], use_flipped='False')\n",
      "Setting up image database: DeepScores_2017_train\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data1/dbashir/Project/Summer2018/DeepWatershedDetection/data/DeepScores_2017/train_val_test/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-509d83d9b566>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-1e75b91f89e7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(parsed)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# load database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroidb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroidb_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_layer_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mnr_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-e82100641e24>\u001b[0m in \u001b[0;36mload_database\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Setting up image database: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_imdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loaded dataset `{:s}` for training'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mroidb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_roidb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_flipped\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/dbashir/Project/Summer2018/DeepWatershedDetection/lib/datasets/factory.py\u001b[0m in \u001b[0;36mget_imdb\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__sets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown dataset: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m__sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/dbashir/Project/Summer2018/DeepWatershedDetection/lib/datasets/factory.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(split, year)\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'debug'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train100'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train10000'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test100'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DeepScores_{}_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0m__sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeep_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Set up coco_2014_<split>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/dbashir/Project/Summer2018/DeepWatershedDetection/lib/datasets/deep_scores.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_set, year, devkit_path)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_image_set_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Default to roidb handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_roidb_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_roidb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/dbashir/Project/Summer2018/DeepWatershedDetection/lib/datasets/deep_scores.py\u001b[0m in \u001b[0;36m_load_image_set_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m#read according file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_set\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m       \u001b[0mallowed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data1/dbashir/Project/Summer2018/DeepWatershedDetection/data/DeepScores_2017/train_val_test/train.txt'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # default arguments for deep-scores\n",
    "\n",
    "    parser.add_argument(\"--scale_list\", type=list, default=[0.5], help=\"global scaling factor randomly chosen from this list\")\n",
    "    parser.add_argument(\"--crop\", type=str, default=\"True\", help=\"should images be cropped\")\n",
    "    parser.add_argument(\"--crop_top_left_bias\", type=float, default=0.3, help=\"fixed probability that the crop will be from the top left corner\")\n",
    "    parser.add_argument(\"--max_edge\", type=int, default=960, help=\"if there is no cropping - scale such that the longest edge has this size / if there is cropping crop to max_edge * max_edge\")\n",
    "    parser.add_argument(\"--use_flipped\", type=str, default=\"False\", help=\"wether or not to append Horizontally flipped images\")\n",
    "    parser.add_argument(\"--substract_mean\", type=str, default=\"False\", help=\"wether or not to substract the mean of the VOC images\")\n",
    "    parser.add_argument(\"--pad_to\", type=int, default=160, help=\"pad the final image to have edge lengths that are a multiple of this - use 0 to do nothing\")\n",
    "    parser.add_argument(\"--pad_with\", type=int, default=0,help=\"use this number to pad images\")\n",
    "\n",
    "    parser.add_argument(\"--prefetch\", type=str, default=\"True\", help=\"use additional process to fetch batches\")\n",
    "    parser.add_argument(\"--prefetch_len\", type=int, default=7, help=\"prefetch queue len\")\n",
    "\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=1, help=\"batch size for training\") # code only works with batchsize 1!\n",
    "    parser.add_argument(\"--continue_training\", type=str, default=\"False\", help=\"load checkpoint\")\n",
    "    parser.add_argument(\"--pretrain_lvl\", type=str, default=\"semseg\", help=\"What kind of pretraining to use: no,class,semseg\")\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=1e-4, help=\"Learning rate for Adam Optimizer\")\n",
    "    parser.add_argument(\"--dataset\", type=str, default=\"DeepScores_2017_train\", help=\"DeepScores, voc or coco\")\n",
    "    parser.add_argument(\"--dataset_validation\", type=str, default=\"DeepScores_2017_debug\", help=\"DeepScores, voc, coco or no - validation set\")\n",
    "    parser.add_argument(\"--print_interval\", type=int, default=10, help=\"after how many iterations is tensorboard updated\")\n",
    "    parser.add_argument(\"--tensorboard_interval\", type=int, default=50, help=\"after how many iterations is tensorboard updated\")\n",
    "    parser.add_argument(\"--save_interval\", type=int, default=1000, help=\"after how many iterations are the weights saved\")\n",
    "    parser.add_argument(\"--nr_classes\", type=list, default=[],help=\"ignore, will be overwritten by program\")\n",
    "\n",
    "    parser.add_argument('--model', type=str, default=\"RefineNet-Res101\", help=\"Base model -  Currently supports: RefineNet-Res50, RefineNet-Res101, RefineNet-Res152\")\n",
    "\n",
    "    parser.add_argument('--training_help', type=list, default=[None], help=\"sample gt into imput\")\n",
    "\n",
    "    parser.add_argument('--training_assignements', type=list,\n",
    "                        default=[\n",
    "    # energy markers\n",
    "                            {'ds_factors': [1], 'downsample_marker': True, 'overlap_solution': 'max',\n",
    "                                 'stamp_func': 'stamp_energy', 'layer_loss_aggregate': 'avg', 'mask_zeros': False,\n",
    "                                 'stamp_args':{'marker_dim': (9,9),'size_percentage': 0.8, \"shape\": \"oval\", \"loss\": \"softmax\", \"energy_shape\": \"linear\"}},\n",
    "    # # class markers\n",
    "                            {'ds_factors': [1], 'downsample_marker': True, 'overlap_solution': 'no',\n",
    "                             'stamp_func': 'stamp_class', 'layer_loss_aggregate': 'avg', 'mask_zeros': True,\n",
    "                             'stamp_args': {'marker_dim': (9,9), 'size_percentage': 1, \"shape\": \"oval\", \"class_resolution\": \"class\", \"loss\": \"softmax\"}},\n",
    "    # # bbox markers\n",
    "    #                         {'ds_factors': [1], 'downsample_marker': True, 'overlap_solution': 'nearest',\n",
    "    #                          'stamp_func': 'stamp_bbox', 'layer_loss_aggregate': 'avg', 'mask_zeros': False,\n",
    "    #                          'stamp_args': {'marker_dim': (9,9), 'size_percentage': 1, \"shape\": \"oval\", \"loss\": \"reg\"}},\n",
    "\n",
    "    # bbox markers\n",
    "                            {'ds_factors': [1], 'downsample_marker': True, 'overlap_solution': 'nearest',\n",
    "                             'stamp_func': 'stamp_bbox', 'layer_loss_aggregate': 'avg', 'mask_zeros': True,\n",
    "                             'stamp_args': {'marker_dim': (9,9), 'size_percentage': 1, \"shape\": \"oval\", \"loss\": \"reg\"}}\n",
    "\n",
    "                        ],help=\"configure how groundtruth is built, see datasets.fcn_groundtruth\")\n",
    "\n",
    "\n",
    "    parser.add_argument('--do_assign', type=list,\n",
    "                        default=[\n",
    "                            {\"assign\": 1, \"help\": 0, \"Itrs\": 5},\n",
    "                            {\"assign\": 0, \"help\": 0, \"Itrs\": 5},\n",
    "                            {\"assign\": 2, \"help\": 0, \"Itrs\": 3000}\n",
    "\n",
    "                        ], help=\"configure how assignements get repeated\")\n",
    "\n",
    "    parser.add_argument('--combined_assignements', type=list,\n",
    "                        default=[{\"assigns\": [0,1,2], \"loss_factors\": [2,1,1], \"Running_Mean_Length\": 5, \"Itrs\": 30000}],help=\"configure how groundtruth is built, see datasets.fcn_groundtruth\")\n",
    "\n",
    "    parsed = parser.parse_known_args()\n",
    "\n",
    "    main(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
